<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="metrica">
<title>Available prediction performance metrics and indices • metrica</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.0/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.0/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Available prediction performance metrics and indices">
<meta property="og:description" content="metrica">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">metrica</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.0.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/available_metrics.html">Available prediction performance metrics and indices</a>
    <a class="dropdown-item" href="../articles/classification_case.html">Classification case: Assessing classification quality</a>
    <a class="dropdown-item" href="../articles/regression_case.html">Regression case: Assessing model agreement in wheat grain nitrogen content prediction</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/adriancorrendo/metrica/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="available_metrics_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Available prediction performance metrics and indices</h1>
                        <h4 data-toc-skip class="author">Adrian Correndo</h4>
            
            <h4 data-toc-skip class="date">2022-06-28</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/adriancorrendo/metrica/blob/HEAD/vignettes/available_metrics.Rmd" class="external-link"><code>vignettes/available_metrics.Rmd</code></a></small>
      <div class="d-none name"><code>available_metrics.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="performance-metrics-available-in-metrica">Performance metrics available in <em>metrica</em><a class="anchor" aria-label="anchor" href="#performance-metrics-available-in-metrica"></a>
</h2>
<p>The <strong>metrica</strong> package compiles +80 functions to assess regression (continuous) and classification (categorical) prediction performance from multiple perspectives. <br></p>
<p>For regression models, it includes 4 plotting functions (scatter, tiles, density, &amp; Bland-Altman plots), and 48 prediction performance scores including error metrics (MBE, MAE, RAE, RMAE, MAPE, SMAPE, MSE, RMSE, RRMSE, RSR, PBE, iqRMSE), model efficiency (NSE, E1, Erel, KGE), indices of agreement (d, d1, d1r, RAC, AC, lambda), goodness of fit (r, R2, RSS, TSS, RSE), adjusted correlation coefficients (CCC, Xa, distance correlation-dcorr-), error decomposition (MLA, MLP, PLA, PLP, PAB, PPB, SB, SDSD, LCS, Ub, Uc, Ue), variability (uSD, var_u), and symmetric regression coefficients (B0_sma, B1_sma). Specifically for time-series predictions, <code>metrica</code> also includes the Mean Absolute Scaled Error (MASE). <br></p>
<p>For classification (binomial and multinomial) tasks, it includes a function to visualize the confusion matrix using ggplot2, and 27 functions of prediction scores including: accuracy, error rate, precision, recall, specificity, balanced accuracy, F-score, adjusted F-score, G-mean, Bookmaker Informedness (Youden’s J-index), Markedness (deltaP), Matthews Correlation Coefficient, khat or Cohen’s Kappa, negative predictive value, positive and negative likelihood ratios, diagnostic odds ratio, prevalence, critical success index, false positive rate, false negative rate, false detection rate, false omission rate, and area under the ROC curve. <br></p>
<p>Always keep in mind the concept of “cross-validation” since predicted values should come from out-of-bag samples (unseen by training set) to avoid overestimation of the prediction performance. <br></p>
</div>
<div class="section level2">
<h2 id="core-functions-arguments-">Core functions’ arguments. <br><a class="anchor" aria-label="anchor" href="#core-functions-arguments-"></a>
</h2>
<p>There are two basic arguments common to all <code>metrica</code> functions: (i) <code>obs</code>(Oi; observed, a.k.a. actual, measured, truth, target, label), and (ii) <code>pred</code> (Pi; predicted, a.k.a. simulated, fitted, modeled, estimate) values. <br></p>
<p>Optional arguments include <code>data</code> that allows to call an existing data frame containing both observed and predicted vectors, and <code>tidy</code>, which controls the type of output as a list (tidy = FALSE) or as a data.frame (tidy = TRUE). <br></p>
<p>For regression, some specific functions for regression also require to define the axis <code>orientation</code>. For example, the slope of the symmetric linear regression describing the bivariate scatter (SMA). <br></p>
<p>For binary classification (two classes), functions also require to check the <code>pos_level</code> arg., which indicates the alphanumeric order of the “positive level”. Normally, the most common binary denominations are c(0,1), c(“Negative”, “Positive”), c(“FALSE”, “TRUE”), so the default pos_level = 2 (1, “Positive”, “TRUE”). However, other cases are also possible, such as c(“Crop”, “NoCrop”) for which the user needs to specify pos_level = 1. <br></p>
<p>For multiclass classification tasks, some functions present the <code>atom</code> arg. (logical TRUE / FALSE), which controls the output to be an overall average estimate across all classes, or a class-wise estimate. For example, user might be interested in obtaining estimates of precision and recall for each possible class of the prediction. <br></p>
</div>
<div class="section level2">
<h2 id="list-of-available-prediction-performance-metrics">List of available prediction performance metrics <br><a class="anchor" aria-label="anchor" href="#list-of-available-prediction-performance-metrics"></a>
</h2>
</div>
<div class="section level2">
<h2 id="regression-metrics-continuous-variables">1. Regression metrics (continuous variables)<a class="anchor" aria-label="anchor" href="#regression-metrics-continuous-variables"></a>
</h2>
<table class="table">
<colgroup>
<col width="2%">
<col width="8%">
<col width="20%">
<col width="36%">
<col width="31%">
</colgroup>
<thead><tr class="header">
<th>#</th>
<th>Metric</th>
<th>Definition</th>
<th>Details</th>
<th>Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>r01</td>
<td><code>RSS</code></td>
<td>Residual sum of squares (a.k.a. as sum of squares)</td>
<td>The sum of squared differences between predicted and observed values. It represents the base of many error metrics using squared scale such as the MSE</td>
<td><img src="../reference/figures/A.RSS.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r02</td>
<td><code>TSS</code></td>
<td>Total sum of squares</td>
<td>The sum of the squared differences between the observations and its mean. It is used as a reference error, for example, to estimate explained variance</td>
<td><img src="../reference/figures/B.TSS.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r03</td>
<td><code>var_u</code></td>
<td>Sample variance, uncorrected</td>
<td>The mean of sum of squared differences between values of an <code>x</code> and its mean (divided by n, not n-1)</td>
<td><img src="../reference/figures/C.var.u.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r4</td>
<td><code>uSD</code></td>
<td>Sample standard deviation, uncorrected</td>
<td>The square root of the mean of sum of squared differences between values of an <code>x</code> and its mean (divided by n, not n-1)</td>
<td><img src="../reference/figures/D.uSD.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r04</td>
<td><code>B0</code></td>
<td>Intercept of SMA regression</td>
<td>SMA is a symmetric linear regression (invariant results/interpretation to axis orientation) recommended to describe the bivariate scatter instead of OLS regression (classic linear model, which results vary with the axis orientation). B0 could be used to test agreement along with B1 (H0: B0 = 0, B1 = 1) . Warton et al. (2006)</td>
<td><img src="../reference/figures/1.B0.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r06</td>
<td><code>B1</code></td>
<td>Slope of SMA regression</td>
<td>SMA is a symmetric linear regression (invariant results/interpretation to axis orientation) recommended to describe the bivariate scatter instead of OLS regression (classic linear model, which results vary with the axis orientation). B1 could be used to test isometry of the PO scatter (H0: B1 = 1). B1 also represents the ratio of standard deviations (So and Sp). Warton et al. (2006)</td>
<td><img src="../reference/figures/2.B1.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r07</td>
<td><code>r</code></td>
<td>Pearson’s correlation coefficient</td>
<td>Strength of linear association between P and O. However, it measures “precision” but no accuracy. Kirch (2008)</td>
<td><img src="../reference/figures/3.r.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r8</td>
<td><code>R2</code></td>
<td>Coefficient of determination</td>
<td>Strength of linear association between P and O. However, it measures “precision” but no accuracy</td>
<td><img src="../reference/figures/4.R2.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r09</td>
<td><code>Xa</code></td>
<td>Accuracy coefficient</td>
<td>Measures accuracy. Used to adjust the precision measured by <code>r</code> to estimate agreement</td>
<td><img src="../reference/figures/5.Xa.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r10</td>
<td><code>CCC</code></td>
<td>Concordance correlation coefficient</td>
<td>Tests agreement. It presents both precision (r) and accuracy (Xa) components. Easy to interpret. Lin (1989)</td>
<td><img src="../reference/figures/6.CCC.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r11</td>
<td><code>MAE</code></td>
<td>Mean Absolute Error</td>
<td>Measures both lack of accuracy and precision in absolute scale. It keeps the same units than the response variable. Less sensitive to outliers than the MSE or RMSE. Willmott &amp; Matsuura (2005)</td>
<td><img src="../reference/figures/7.MAE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r12</td>
<td><code>RMAE</code></td>
<td>Relative Mean Absolute Error</td>
<td>Normalizes the MAE with respect to the mean of observations</td>
<td><img src="../reference/figures/8.RMAE.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r13</td>
<td><code>MAPE</code></td>
<td>Mean Absolute Percentage Error</td>
<td>Percentage units (independent scale). Easy to explain and to compare performance across models with different response variables. Asymmetric and unbounded.</td>
<td><img src="../reference/figures/9.MAPE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r14</td>
<td><code>SMAPE</code></td>
<td>Symmetric Mean Absolute Percentage Error</td>
<td>SMAPE tackles the asymmetry issues of MAPE and includes lower (0%) and upper (200%) bounds. Makridakis (1993)</td>
<td><img src="../reference/figures/10.SMAPE.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r15</td>
<td><code>RAE</code></td>
<td>Relative Absolute Error</td>
<td>RAE normalizes MAE with respect to the total absolute error. Lower bound at 0 (perfect fit) and no upper bound (infinity)</td>
<td><img src="../reference/figures/11.RAE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r16</td>
<td><code>RSE</code></td>
<td>Relative Squared Error</td>
<td>Proportion of the total sum of squares that corresponds to differences between predictions and observations (residual sum of squares)</td>
<td><img src="../reference/figures/12.RSE.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r17</td>
<td><code>MBE</code></td>
<td>Mean Bias Error</td>
<td>Main bias error metric. Same units as the response variable. Related to differences between means of predictions and observations. Negative values indicate overestimation. Positive values indicate underestimation. Unbounded. Also known as average error. Janssen &amp; Heuberger (1995)</td>
<td><img src="../reference/figures/13.MBE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r18</td>
<td><code>PBE</code></td>
<td>Percentage Bias Error</td>
<td>Useful to identify systematic over or under predictions. Percentage units. As the MBE, PBE negative values indicate overestimation, while positive values indicate underestimation. Unbounded. Gupta et al. (1999)</td>
<td><img src="../reference/figures/14.PBE.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r19</td>
<td><code>PAB</code></td>
<td>Percentage Additive Bias</td>
<td>Percentage of the MSE related to systematic additive issues on the predictions. Related to difference of the means of predictions and observations</td>
<td><img src="../reference/figures/15.PAB.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r20</td>
<td><code>PPB</code></td>
<td>Percentage Proportional Bias</td>
<td>Percentage of the MSE related to systematic proportionality issues on the predictions. Related to slope of regression line describing the bivariate scatter</td>
<td><img src="../reference/figures/16.PPB.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r21</td>
<td><code>MSE</code></td>
<td>Mean Squared Error</td>
<td>Comprises both accuracy and precision. High sensitivity to outliers</td>
<td><img src="../reference/figures/17.MSE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r22</td>
<td><code>RMSE</code></td>
<td>Root Mean Squared Error</td>
<td>Comprises both precision and accuracy, has the same units than the variable of interest. Very sensitive to outliers</td>
<td><img src="../reference/figures/18.RMSE.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r23</td>
<td><code>RRMSE</code></td>
<td>Relative Root Mean Squared Error</td>
<td>RMSE normalized by the mean of observations</td>
<td><img src="../reference/figures/19.RRMSE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r24</td>
<td><code>RSR</code></td>
<td>Root Mean Standard Deviation Ratio</td>
<td>RMSE normalized by the standard deviation of observations. Moriasi et al. (2007)</td>
<td><img src="../reference/figures/20.RSR.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r25</td>
<td><code>iqRMSE</code></td>
<td>Inter-quartile Normalized Root Mean Squared Error</td>
<td>RMSE normalized by the interquartile range length (between percentiles 25th and 75th)</td>
<td><img src="../reference/figures/21.iqRMSE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r26</td>
<td><code>MLA</code></td>
<td>Mean Lack of Accuracy</td>
<td>Bias component of MSE decomposition. Correndo et al. (2021)</td>
<td><img src="../reference/figures/22.MLA.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r27</td>
<td><code>MLP</code></td>
<td>Mean Lack of Precision</td>
<td>Variance component of MSE decomposition. Correndo et al. (2021)</td>
<td><img src="../reference/figures/23.MLP.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r29</td>
<td><code>PLA</code></td>
<td>Percentage Lack of Accuracy</td>
<td>Percentage of the MSE related to lack of accuracy (systematic differences) on the predictions. Correndo et al. (2021)</td>
<td><img src="../reference/figures/24.PLA.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r29</td>
<td><code>PLP</code></td>
<td>Percentage Lack of Precision</td>
<td>Percentage of the MSE related to lack of precision (unsystematic differences) on the predictions. Correndo et al. (2021)</td>
<td><img src="../reference/figures/25.PLP.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r30</td>
<td><code>SB</code></td>
<td>Squared Bias</td>
<td>Additive bias component, MSE decomposition. Kobayashi and Salam (2000)</td>
<td><img src="../reference/figures/26.SB.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r31</td>
<td><code>SDSD</code></td>
<td>Product of Standard Deviations</td>
<td>Proportional bias component, MSE decomposition. Kobayashi and Salam (2000)</td>
<td><img src="../reference/figures/27.SDSD.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r32</td>
<td><code>LCS</code></td>
<td>Lack of Correlation</td>
<td>Random error component, MSE decomposition. Kobayashi and Salam (2000)</td>
<td><img src="../reference/figures/28.LCS.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r33</td>
<td><code>Ue</code></td>
<td>Random error proportion</td>
<td>The Ue estimates the proportion of the total sum of squares related to the random error (unsystematic error or variance) following the sum of squares decomposition suggested by Smith and Rose (1995) also known as Theil’s partial inequalities</td>
<td><img src="../reference/figures/29.Ue.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r34</td>
<td><code>Uc</code></td>
<td>Lack of Consistency error proportion</td>
<td>The Uc estimates the proportion of the total sum of squares related to the lack of consistency (proportional bias) following the sum of squares decomposition suggested by Smith and Rose (1995) also known as Theil’s partial inequalities</td>
<td><img src="../reference/figures/30.Uc.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r35</td>
<td><code>Ub</code></td>
<td>Mean Bias error proportion</td>
<td>The Ub estimates the proportion of the total sum of squares related to the mean bias following the sum of squares decomposition suggested by Smith and Rose (1995) also known as Theil’s partial inequalities</td>
<td><img src="../reference/figures/31.Ub.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r36</td>
<td><code>NSE</code></td>
<td>Nash and Sutcliffe’s Model Efficiency</td>
<td>Model efficiency using squared residuals normalized by the variance of observations. Nash and Sutcliffe (1970)</td>
<td><img src="../reference/figures/32.NSE.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r37</td>
<td><code>E1</code></td>
<td>Absolute Model Efficiency</td>
<td>Model efficiency. Modification of NSE using absolute residuals instead of squared residuals. Legates and McCabe (1999)</td>
<td><img src="../reference/figures/33.E1.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r38</td>
<td><code>Erel</code></td>
<td>Relative Model Efficiency</td>
<td>Compared to the NSE, the Erel is suggested as more sensitive to systematic over- or under-predictions. Krause et al. (2005)</td>
<td><img src="../reference/figures/34.Erel.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r39</td>
<td><code>KGE</code></td>
<td>Kling-Gupta Model Efficiency</td>
<td>Model efficiency with accuracy, precision, and consistency components. Kling et al. (2012)</td>
<td><img src="../reference/figures/35.KGE.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r40</td>
<td><code>d</code></td>
<td>Index of Agreement</td>
<td>Measures accuracy and precision using squared residuals. Dimensionless (normalized). Bounded [0;1]. Asymmetric Willmott (1981)</td>
<td><img src="../reference/figures/36.d.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r41</td>
<td><code>d1</code></td>
<td>Modified Index of Agreement</td>
<td>Measures accuracy and precision using absolute residuals(1). Dimensionless (normalized). Bounded [0;1]. Asymmetric Willmott et al. (1985)</td>
<td><img src="../reference/figures/37.d1.gif" alt="equation"></td>
</tr>
<tr class="even">
<td>r42</td>
<td><code>d1r</code></td>
<td>Refined Index of Agreement</td>
<td>Refines d1 by a modification on the denominator (potential error) to normalize absolute error. Willmott et al. (2012)</td>
<td><img src="../reference/figures/38.d1r.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r43</td>
<td><code>RAC</code></td>
<td>Robinson’s Agreement Coefficient</td>
<td>RAC measures both accuracy and precision (general agreement). Dimensionless (normalized). Bounded [0;1]. Symmetric. Robinson (1957; 1959)</td>
<td>
<img src="../reference/figures/39a.RAC.gif" alt="equation"><br> where <br><img src="../reference/figures/39b.RAC.gif" alt="equation">
</td>
</tr>
<tr class="even">
<td>r44</td>
<td><code>AC</code></td>
<td>Ji and Gallo’s Agreement Coefficient</td>
<td>AC measures both accuracy and precision (general agreement). Dimensionless (normalized). Positively bounded [-infinity;1]. Symmetric. Ji and Gallo (2006)</td>
<td><img src="../reference/figures/40.AC.gif" alt="equation"></td>
</tr>
<tr class="odd">
<td>r45</td>
<td><code>lambda</code></td>
<td>Duveiller’s Lambda Coefficient</td>
<td>
<code>lambda</code> measures both accuracy and precision. Dimensionless (normalized). Bounded [-1;1]. Symmetric. Equivalent to CCC when <code>r</code> is greater or equal to 0. Duveiller et al. (2016)</td>
<td>
<img src="../reference/figures/41a.lambda.gif" alt="equation"><br> where <br><img src="../reference/figures/41b.lambda.gif" alt="equation">, <br> otherwise <br><img src="../reference/figures/41c.lambda.gif" alt="equation">
</td>
</tr>
<tr class="even">
<td>r46</td>
<td><code>dcorr</code></td>
<td>Distance correlation</td>
<td>Measures the dependency between to random vectors. Compared to Pearson’s <code>r</code>, it offers the advantage of considering both linear and nonlinear association patterns. It is based on a matrix of centered Euclidean distances compared to the distance of many shuffles of the data. It is dimensionless, bounded [0;1], and symmetric. <code>dcorr = 0</code> characterizes independence between vectors. The closest to 1 the better. A disadvantage for the predicted-observed case is that values can be negatively correlated but producing a <code>dcorr</code> close to 1. Székely (2007)</td>
<td>
<span class="math inline">\(dcorr = \sqrt{\frac{\mathcal{V}^2_n~(\mathbf{P,O})}{ {\sqrt{\mathcal{V}^2_n (\mathbf{P}) \mathcal{V}^2_n(\mathbf{O})} } }}\)</span> See Székely (2007) for full details</td>
</tr>
<tr class="odd">
<td>r47</td>
<td><code>MIC</code></td>
<td>Maximal Information Coefficient</td>
<td>Measures association between two variables based on “binning” (a.k.a. data bucketing) to reduce the influence of small observation errors. It is based on the “mutual information” concept of information theory, which measures the mutual dependence between two variables. It is dimensionless (normalized), bounded [0;1], and symmetric. Reshef et al. (2011)</td>
<td>See Reshef et al. 2011</td>
</tr>
<tr class="even">
<td>r48</td>
<td><code>MASE</code></td>
<td>Mean Absolute Scaled Error</td>
<td>The <code>MASE</code> is especially well suited for time series predictions, as it scales (or normalize) the error based on <em>in-sample</em> MAE from the naive forecast method (a.k.a. random walk). It is dimensionless (normalized) and symmetric. The reference score is MASE = 1, which indicates that the model performs the same than a naive forecast (error with respect to previous historical observation). MASE &lt;1 indicates that the model performs better than naive forecast, and MASE &gt; 1 indicates a bad performance of the predictions. See Hyndman &amp; Koehler (2006)</td>
<td><span class="math inline">\(MASE = \frac{1}{n}(\frac{|O_i-P_i|}{ \frac{1}{T-1} \sum^T_{t=2}~|O_t - O_{t-1}| })\)</span></td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div class="section level2">
<h2 id="classification-metrics-categorical-variables">2. Classification metrics* (categorical variables)<a class="anchor" aria-label="anchor" href="#classification-metrics-categorical-variables"></a>
</h2>
<p><em>Note: All classification functions automatically recognize the number of classes and adjust estimations for binary or multiclass cases. However, for binary classification tasks, the user would need to check the alphanumeric order of the level considered as positive. By default “pos_level = 2” based on the most common denominations being c(0,1), c(“Negative”,“Positive”), c(“TRUE”, “FALSE”).</em> <br></p>
<table class="table">
<colgroup>
<col width="2%">
<col width="8%">
<col width="21%">
<col width="52%">
<col width="14%">
</colgroup>
<thead><tr class="header">
<th>#</th>
<th>Metric</th>
<th>Definition</th>
<th>Details</th>
<th>Formula</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>c1</td>
<td><code>accuracy</code></td>
<td>Accuracy</td>
<td>It is the most commonly used metric to evaluate classification quality. It represents the number of corrected classified cases with respect to all cases. However, be aware that this metric does not cover all aspects about classification quality. When classes are uneven in number, it may not be a reliable metric.</td>
<td><span class="math inline">\(accuracy = \frac{TP+TN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="even">
<td>c2</td>
<td><code>error_rate</code></td>
<td>Error Rate</td>
<td>It represents the complement of accuracy. It could vary between 0 and 1. Being 0 the best and 1 the worst</td>
<td><span class="math inline">\(error~rate = \frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="odd">
<td>c3</td>
<td><code>precision</code></td>
<td>Precision</td>
<td>Also known as positive predictive value (PPV), it represents the proportion of well classified cases with respect to the total of cases predicted with a given class (multinomial) or the true class (binomial)</td>
<td><span class="math inline">\(precision = \frac{TP}{TP + FP}\)</span></td>
</tr>
<tr class="even">
<td>c4</td>
<td><code>recall</code></td>
<td>Recall</td>
<td>Also known as sensitivity, hit rate, or true positive rate (TPR) for binary cases. It represents the proportion of well predicted cases with respect to the total number of observed cases for a given class (multinomial) or the positive class (binomial)</td>
<td><span class="math inline">\(recall = \frac{TP}{P} = 1 - FNR\)</span></td>
</tr>
<tr class="odd">
<td>c5</td>
<td><code>specificity</code></td>
<td>Specificity</td>
<td>Also known as selectivity or true negative rate (TNR). It represents the proportion of well classified negative values with respect to the total number of actual negatives</td>
<td><span class="math inline">\(specificity = \frac{TN}{N} = 1 - FPR\)</span></td>
</tr>
<tr class="even">
<td>c6</td>
<td><code>balacc</code></td>
<td>Balanced Accuracy</td>
<td>This metric is especially useful when the number of observations across classes is imbalanced</td>
<td><span class="math inline">\(b.accuracy = \frac{recall + specificity}{2}\)</span></td>
</tr>
<tr class="odd">
<td>c7</td>
<td><code>fscore</code></td>
<td>F-score</td>
<td>F1-score, F-measure</td>
<td><span class="math inline">\(fscore = \frac{(1 + B ^ 2) * precision * recall}{(B ^ 2 * precision) + recall)}\)</span></td>
</tr>
<tr class="even">
<td>c8</td>
<td><code>agf</code></td>
<td>Adjusted F-score</td>
<td>The agf adjusts the fscore for datasets with imbalanced classes</td>
<td>
<span class="math inline">\(agf = \sqrt{F_2 * invF_{0.5}}\)</span>, where <span class="math inline">\(F_2 = 5 * \frac{recall~*~precision}{(4*recall)~+~precision}\)</span>, and <span class="math inline">\(invF_{0.5} = (\frac{5}{4}) * \frac{recall~*~precision}{(0.5^2 ~*~ recall)~+~precision}\)</span>
</td>
</tr>
<tr class="odd">
<td>c9</td>
<td><code>gmean</code></td>
<td>G-mean</td>
<td>The Geometric Mean (gmean) is a measure that considers a balance between the performance of both majority and minority classes. The higher the value the lower the risk of over-fitting of negative and under-fitting of positive classes</td>
<td><span class="math inline">\(gmean = \sqrt{recall~*~specificity}\)</span></td>
</tr>
<tr class="even">
<td>c10</td>
<td><code>khat</code></td>
<td>K-hat or Cohen’s Kappa Coefficient</td>
<td>The khat is considered a more robust metric than the classic <code>accuracy</code>. It normalizes the accuracy by the possibility of agreement by chance. It is positively bounded to 1, but it is not negatively bounded. The closer to 1, the better the classification quality</td>
<td><span class="math inline">\(khat = \frac{2 * (TP * TN - FN * FP)}{(TP+FP) * (FP+TN) + (TP+FN) * (FN + TN)}\)</span></td>
</tr>
<tr class="odd">
<td>c11</td>
<td><code>mcc</code></td>
<td>Matthews Correlation Coefficient</td>
<td>Also known as phi-coefficient. It is particularly useful when the number of observations belonging to each class is uneven. It varies between 0-1, being 0 the worst and 1 the best. Currently, the mcc estimation is only available for binary cases (two classes)</td>
<td><span class="math inline">\(mcc = \frac{TP * TN - FP * FN}{\sqrt{(TP+FP) * (TP+FN) * (TN+FP) * (TN+FN)}}\)</span></td>
</tr>
<tr class="even">
<td>c12</td>
<td><code>fmi</code></td>
<td>Fowlkes-Mallows Index</td>
<td>The fmi is a metric that measures the similarity between two clusters (predicted and observed). It is equivalent to the square root of the product between precision (PPV) and recall (TPR). It varies between 0-1, being 0 the worst and 1 the best.</td>
<td><span class="math inline">\(fmi = \sqrt{precision * recall} = \sqrt{PPV * TPR}\)</span></td>
</tr>
<tr class="odd">
<td>c13</td>
<td><code>bmi</code></td>
<td>Informedness</td>
<td>Also known as the Bookmaker Informedness, or as the Youden’s J-index. It is a suitable metric when the number of cases for each class is uneven. It varies between</td>
<td><span class="math inline">\(bmi = recall + specificity -1 = TPR + TNR - 1 = \frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="even">
<td>c14</td>
<td><code>posLr</code></td>
<td>Positive Likelihood Ratio</td>
<td>The posLr, also known as LR(+) represents the odds of obtaining a positive prediction for actual positives.</td>
<td><span class="math inline">\(posLr = \frac{recall}{1+specificity} = \frac{TPR}{FPR}\)</span></td>
</tr>
<tr class="odd">
<td>c15</td>
<td><code>negLr</code></td>
<td>Negative Likelihood Ratio</td>
<td>The negLr, also known as LR(-) indicates the odds of obtaining a negative prediction for actual positives (or non-negatives in multiclass) relative to the probability of actual negatives of obtaining a negative prediction</td>
<td><span class="math inline">\(negLr = \frac{1-recall}{specificity} = \frac{FNR}{TNR}\)</span></td>
</tr>
<tr class="even">
<td>c16</td>
<td><code>dor</code></td>
<td>Diagnostic Odds Ratio</td>
<td>The dor is a metric summarizing the effectiveness of classification. It represents the odds of a positive case obtaining a positive prediction result with respect to the odds of actual negatives obtaining a positive result</td>
<td><span class="math inline">\(dor = \frac{posLr}{negLr}\)</span></td>
</tr>
<tr class="odd">
<td>c17</td>
<td><code>npv</code></td>
<td>Negative predictive Value</td>
<td>It represents the complement of accuracy. It could vary between 0 and 1. Being 0 the best and 1 the worst</td>
<td><span class="math inline">\(npv = \frac{TP}{PP} = \frac{TP}{TP + FP}\)</span></td>
</tr>
<tr class="even">
<td>c18</td>
<td><code>FPR</code></td>
<td>False Positive Rate</td>
<td>It represents the complement of <code>specificity</code>. It could vary between 0 and 1. The lower the better.</td>
<td><span class="math inline">\(FPR = 1 - specificity = 1 - TNR = \frac{FP}{N}\)</span></td>
</tr>
<tr class="odd">
<td>c19</td>
<td><code>FNR</code></td>
<td>False Negative Rate</td>
<td>It represents the complement of <code>recall</code>. It could vary between 0 and 1. The lower the better.</td>
<td><span class="math inline">\(FNR = 1 - recall = 1 - TPR = \frac{FN}{P}\)</span></td>
</tr>
<tr class="even">
<td>c20</td>
<td><code>FDR</code></td>
<td>False Detection Rate</td>
<td>It represents the complement of <code>precision</code> (or positive predictive value -<code>PPV</code>-). It could vary between 0 and 1, being 0 the best and 1 the worst</td>
<td><span class="math inline">\(FDR = 1 - precision = \frac{FP}{PP} = \frac{FP}{TP + FP}\)</span></td>
</tr>
<tr class="odd">
<td>c21</td>
<td><code>FOR</code></td>
<td>False Omission Rate</td>
<td>It represents the complement of the <code>npv</code>. It could vary between 0 and 1, being 0 the best and 1 the worst</td>
<td><span class="math inline">\(FOR = 1 - npv = \frac{FN}{PN} = \frac{FN}{TN + FN}\)</span></td>
</tr>
<tr class="even">
<td>c22</td>
<td><code>preval</code></td>
<td>Error Rate</td>
<td>It represents the complement of accuracy. It could vary between 0 and 1. Being 0 the best and 1 the worst</td>
<td><span class="math inline">\(error~rate = \frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="odd">
<td>c23</td>
<td><code>preval_t</code></td>
<td>Error Rate</td>
<td>It represents the complement of accuracy. It could vary between 0 and 1. Being 0 the best and 1 the worst</td>
<td><span class="math inline">\(error~rate = \frac{FP+FN}{TP+FP+TN+FN}\)</span></td>
</tr>
<tr class="even">
<td>c24</td>
<td><code>csi</code></td>
<td>Critical Success Index</td>
<td>The <code>csi</code> is also known as the threat score (TS). It could vary between 0 and 1, being 0 the worst and 1 the best</td>
<td><span class="math inline">\(csi = \frac{TP}{TP+FP+TN}\)</span></td>
</tr>
<tr class="odd">
<td>c25</td>
<td><code>deltap</code></td>
<td>Markedness or deltap</td>
<td>The <code>deltap</code> is a metric that quantifies the probability that a condition is marked by the predictor with respect to a random chance</td>
<td><span class="math inline">\(deltap = precision+npv-1 = PPV + NPV -1\)</span></td>
</tr>
<tr class="even">
<td>c26</td>
<td><code>AUC_roc</code></td>
<td>Area Under the Curve</td>
<td>The <code>AUC_roc</code> estimates the area under the receiving operator characteristic curve following the trapezoid approach. It bounded between 0 and 1. The closet to 1 the better. AUC_roc = 0.5 means the models predictions are the same than a random classifier.</td>
<td><span class="math inline">\(AUC_{roc} = precision+npv-1 = PPV + NPV -1\)</span></td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div class="section level2">
<h2 id="references">3. References: <br><a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
</div>
<div class="section level2">
<h2 id="regression">3.1. Regression <br><a class="anchor" aria-label="anchor" href="#regression"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Correndo et al. (2021). Revisiting linear regression to test agreement in continuous predicted-observed datasets. <em>Agric. Syst. 192, 103194.</em>  <br></p></li>
<li><p>Duveiller et al. (2016). Revisiting the concept of a symmetric index of agreement for continuous datasets. <em>Sci. Rep. 6, 1-14.</em>  <br></p></li>
<li><p>Gupta et al. (1999). Status of automatic calibration for hydrologic models: Comparison with multilevel expert calibration. <em>J. Hydrologic Eng. 4(2): 135-143.</em>  <br></p></li>
<li><p>Janssen &amp; Heuberger (1995). Calibration of process-oriented models. <em>Ecol. Modell. 83, 55-66.</em>  <br></p></li>
<li><p>Ji &amp; Gallo (2006). An agreement coefficient for image comparison. <em>Photogramm. Eng. Remote Sensing 7, 823–833.</em>  <br></p></li>
<li><p>Kling et al. (2012). Runoff conditions in the upper Danube basin under an ensemble of climate change scenarios. <em>J. Hydrol., 424-425, 264-277.</em>  <br></p></li>
<li><p>Kirch (2008). Pearson’s Correlation Coefficient. <em>In: Kirch W. (eds) Encyclopedia of Public Health. Springer, Dordrecht.</em>  <br></p></li>
<li><p>Krause et al. (2005). Comparison of different efficiency criteria for hydrological model assessment. <em>Adv. Geosci. 5, 89–97.</em>  <br></p></li>
<li><p>Kobayashi &amp; Salam (2000). Comparing simulated and measured values using mean squared deviation and its components. <em>Agron. J. 92, 345–352.</em>  <br></p></li>
<li><p>Legates &amp; McCabe (1999). Evaluating the use of “goodness-of-fit” measures in hydrologic and hydroclimatic model validation. <em>Water Resour. Res.</em>  <br></p></li>
<li><p>Lin (1989). A concordance correlation coefficient to evaluate reproducibility. <em>Biometrics 45 (1), 255–268.</em>  <br></p></li>
<li><p>Makridakis (1993). Accuracy measures: theoretical and practical concerns. <em>Int. J. Forecast. 9, 527-529.</em>  <br></p></li>
<li><p>Moriasi et al. (2007). Model Evaluation Guidelines for Systematic Quantification of Accuracy in Watershed Simulations. <em>Trans. ASABE 50, 885–900.</em>  <br></p></li>
<li><p>Nash &amp; Sutcliffe (1970). River flow forecasting through conceptual models part I - A discussion of principles. <em>J. Hydrol. 10(3), 292-290.</em>  <br></p></li>
<li><p>Robinson (1957). The statistical measurement of agreement. <em>Am. Sociol. Rev. 22(1), 17-25.</em>  <br></p></li>
<li><p>Robinson (1959). The geometric interpretation of agreement. <em>Am. Sociol. Rev. 24(3), 338-345.</em>  <br></p></li>
<li><p>Smith &amp; Rose (1995). Model goodness-of-fit analysis using regression and related techniques. <em>Ecol. Model. 77, 49–64.</em>  <br></p></li>
<li><p>Warton et al. (2006). Bivariate line-fitting methods for allometry. <em>Biol. Rev. Camb. Philos. Soc. 81, 259–291.</em>  <br></p></li>
<li><p>Willmott (1981). On the validation of models. <em>Phys. Geogr. 2, 184–194.</em>  <br></p></li>
<li><p>Willmott et al. (1985). Statistics for the evaluation and comparison of models. <em>J. Geophys. Res. 90, 8995.</em>  <br></p></li>
<li><p>Willmott &amp; Matsuura (2005). Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance. <em>Clim. Res. 30, 79–82.</em>  <br></p></li>
<li><p>Willmott et al. (2012). A refined index of model performance. <em>Int. J. Climatol. 32, 2088–2094.</em>  <br></p></li>
<li><p>Yang et al. (2014). An evaluation of the statistical methods for testing the performance of crop models with observed data. <em>Agric. Syst. 127, 81-89.</em>  <br></p></li>
<li><p>Szekely, G.J., Rizzo, M.L., and Bakirov, N.K. (2007). Measuring and testing dependence by correlation of distances. <em>Annals of Statistics, Vol. 35(6): 2769-2794.</em>  <br></p></li>
<li><p>Reshef, D., Reshef, Y., Finucane, H., Grossman, S., McVean, G., Turnbaugh, P., Lander, R., Mitzenmacher, M., and Sabeti, P. (2011). Detecting novel associations in large datasets. <em>Science 334, 6062</em>. </p></li>
<li><p>Hyndman, R.J., Koehler, A.B. (2006). Another look at measures of forecast accuracy. <em>Int. J. Forecast</em> </p></li>
</ol>
<p><br></p>
</div>
<div class="section level2">
<h2 id="classification">3.2. Classification <br><a class="anchor" aria-label="anchor" href="#classification"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>Ting K.M. (2017). Confusion Matrix. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining. Springer, Boston, MA.</em> </p></li>
<li><ol start="2017" style="list-style-type: decimal">
<li>Accuracy. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining</em> <em>. Springer, Boston, MA.</em> </li>
</ol></li>
<li><p>García, V., Mollineda, R.A., Sánchez, J.S. (2009). Index of Balanced Accuracy: A Performance Measure for Skewed Class Distributions. <em>In: Araujo, H., Mendonça, A.M., Pinho, A.J., Torres, M.I. (eds) Pattern Recognition and Image Analysis. IbPRIA 2009. Lecture Notes in Computer Science, vol 5524. Springer-Verlag Berlin Heidelberg.</em> </p></li>
<li><p>Ting K.M. (2017). Precision and Recall. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining. Springer, Boston, MA.</em> </p></li>
<li><ol start="2017" style="list-style-type: decimal">
<li>Sensitivity. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining. Springer, Boston, MA.</em> </li>
</ol></li>
<li><p>Ting K.M. (2017). Sensitivity and Specificity. <em>In: Sammut C., Webb G.I. (eds) Encyclopedia of Machine Learning and Data Mining. Springer, Boston, MA.</em> </p></li>
<li><p>Trevethan, R. (2017). Sensitivity, Specificity, and Predictive Values: Foundations, Pliabilities, and Pitfalls in Research and Practice. <em>Front. Public Health 5:307</em> </p></li>
<li><p>Goutte, C., Gaussier, E. (2005). A Probabilistic Interpretation of Precision, Recall and F-Score, with Implication for Evaluation. <em>In: D.E. Losada and J.M. Fernandez-Luna (Eds.): ECIR 2005. Advances in Information Retrieval LNCS 3408, pp. 345–359, 2. Springer-Verlag Berlin Heidelberg.</em> </p></li>
<li><p>Maratea, A., Petrosino, A., Manzo, M. (2014). Adjusted-F measure and kernel scaling for imbalanced data learning. <em>Inf. Sci. 257: 331-341.</em> </p></li>
<li><p>De Diego, I.M., Redondo, A.R., Fernández, R.R., Navarro, J., Moguerza, J.M. (2022). General Performance Score for classification problems. <em>Appl. Intell. (2022).</em> </p></li>
<li><p>Fowlkes, Edward B; Mallows, Colin L (1983). A method for comparing two hierarchical clusterings. <em>Journal of the American Statistical Association. 78 (383): 553–569.</em> </p></li>
<li><p>Chicco, D., Jurman, G. (2020). The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. <em>BMC Genomics 21, 6 (2020).</em> </p></li>
<li><p>Youden, W.J. (1950). Index for rating diagnostic tests. <em>Cancer 3: 32-35.</em> </p></li>
<li><p>Powers, D.M.W. (2011). Evaluation: From Precision, Recall and F-Measure to ROC, Informedness, Markedness &amp; Correlation. <em>Journal of Machine Learning Technologies 2(1): 37–63.</em> </p></li>
<li><p>Chicco, D., Tötsch, N., Jurman, G. (2021). The Matthews correlation coefficient (MCC) is more reliable than balanced accuracy, bookmaker informedness, and markedness in two-class confusion matrix evaluation. <em>BioData Min 14(1): 13.</em> </p></li>
<li><p>GlasaJeroen, A.S., Lijmer, G., Prins, M.H., Bonsel, G.J., Bossuyta, P.M.M. (2009). The diagnostic odds ratio: a single indicator of test performance. <em>Journal of Clinical Epidemiology 56(11): 1129-1135.</em> </p></li>
<li><p>Wang H., Zheng H. (2013). Negative Predictive Value. <em>In: Dubitzky W., Wolkenhauer O., Cho KH., Yokota H. (eds) Encyclopedia of Systems Biology. Springer, New York, NY.</em> </p></li>
<li><p>Freeman, E.A., Moisen, G.G. (2008). A comparison of the performance of threshold criteria for binary classification in terms of predicted prevalence and kappa. <em>Ecol. Modell. 217(1-2): 45-58.</em> </p></li>
<li><p>Balayla, J. (2020). Prevalence threshold (φe) and the geometry of screening curves. <em>Plos one, 15(10):e0240215.</em> </p></li>
<li><p>Schaefer, J.T. (1990). The critical success index as an indicator of warning skill. Weather and Forecasting 5(4): 570-575. </p></li>
<li><p>Hanley, J.A., McNeil, J.A. (2017). The meaning and use of the area under a receiver operating characteristic (ROC) curve. <em>Radiology 143(1): 29-36</em> </p></li>
<li><p>Hand, D.J., Till, R.J. (2001). A simple generalisation of the area under the ROC curve for multiple class classification problems. <em>Machine Learning 45: 171-186</em> </p></li>
<li><p>Mandrekar, J.N. (2010). Receiver operating characteristic curve in diagnostic test assessment. <em>J. Thoracic Oncology 5(9): 1315-1316</em> </p></li>
</ol>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Adrian A. Correndo, Adrian A. Correndo, Luiz H. Moro Rosso, Rai Schwalbert, Carlos Hernandez, Leonardo M. Bastos, Luciana Nieto, Dean Holzworth, Ignacio A. Ciampitti.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.5.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
